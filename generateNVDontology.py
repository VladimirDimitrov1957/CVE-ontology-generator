"""NVD ontology generator.

The generator downloads the current version of NVD from NIST site and then generates OWL Manchester syntax ontology.
The dictionary is downloaded as .zip file and then it is unzipped.
The ontology is generated with the file name "nvd.owl".
All operations and files are placed in the current directory.
"""

import urllib.request, os, zipfile, json, shutil, re, sys, argparse
from datetime import datetime
from multiprocessing import Process, Queue, Manager, cpu_count, freeze_support
from cpe import *

head = """
Prefix: : <http://www.semanticweb.org/cht_c/nvd#>
Prefix: cpe: <http://www.semanticweb.org/cht_c/cpe#>
Prefix: cwe: <http://www.semanticweb.org/cht_c/cwe#>
Prefix: dc: <http://purl.org/dc/elements/1.1/>
Prefix: owl: <http://www.w3.org/2002/07/owl#>
Prefix: rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
Prefix: rdfs: <http://www.w3.org/2000/01/rdf-schema#>
Prefix: xml: <http://www.w3.org/XML/1998/namespace>
Prefix: xsd: <http://www.w3.org/2001/XMLSchema#>
"""

def codeString(s):
        temp = s.replace("\\", "\\\\")
        return temp.replace("\"", "\\\"")

def processFeed(inQueue, resultQueue, cpeFeeds, modified = None, onlyModifiedCVEs = False):

        class BF:
                with open("shellPart.owl", "r", encoding="utf-8") as iFile:
                        ontoPart = iFile.read()
                with open("shellConfig.owl", "r", encoding="utf-8") as iFile:
                        ontoConfig = iFile.read()
                def newPart(self):
                        self.file_path = "results/o" + self.feedName + str(self.partNo) + ".owl"
                        self.file = open(self.file_path, "w", encoding="utf-8")
                        self.file.write(BF.ontoPart.replace("XXXXX", feedName + str(self.partNo)))
                        self.createdFile = True
                def newCPart(self):
                        self.ontologies.add(self.ontoName)
                        self.cfile_path = "results/" + self.ontoName + ".owl"
                        self.cfile = open(self.cfile_path, "w", encoding="utf-8")
                        self.cfile.write(BF.ontoConfig.replace("XXXXX", self.ontoName))
                        self.createdCFile = True
                def __init__(self, feedName):
                        self.partNo = 0
                        self.cpartNo = 0
                        self.feedName = feedName
                        self.createdFile = False
                        self.ontoName = "o" + feedName + str(self.partNo) + "c" + str(self.cpartNo)
                        self.ontologies = set()
                        self.createdCFile = False
                def write(self, s):
                        if not self.createdFile: self.newPart()
                        self.file.write(s)
                def cwrite(self, s):
                        if not self.createdCFile: self.newCPart()
                        self.cfile.write(s)
                def cflush(self):
                        if not self.createdCFile or os.path.getsize(self.cfile_path) <= 2E8: return
                        self.cclose()
                        self.cpartNo += 1
                        self.ontoName = "o" + self.feedName + str(self.partNo) + "c" + str(self.cpartNo)
                        self.createdCFile = False
                def cclose(self):
                        if self.createdCFile: self.cfile.close()
                def flush(self):
                        if not self.createdCFile or os.path.getsize(self.file_path) <= 2E8: return
                        self.close()
                        self.partNo += 1
                        self.createdFile = False
                        self.cclose()
                        self.cpartNo = 0
                        self.ontoName = "o" + self.feedName + str(self.partNo) + "c" + str(self.cpartNo)
                        self.ontologies = set()
                        self.createdCFile = False
                def getOntoName(self):
                        return self.ontoName
                def close(self):
                        self.cclose()
                        if not self.createdFile: return
                        self.file.close()
                        with open(self.file_path, "r", encoding="utf-8") as iFile:
                                contents = iFile.read()
                        with open(self.file_path, "w", encoding="utf-8") as oFile:
                                c = ""
                                for o in self.ontologies:
                                        c += "\rPrefix: " + o + ": <http://www.semanticweb.org/cht_c/" + o + "#>" + \
                                                "\rImport: <http://www.semanticweb.org/cht_c/" + o + ">"
                                c += "\r\n"
                                oFile.write(contents.replace("Prefix: o: <http://www.semanticweb.org/cht_c/YYYYY>", c))
                def parts(self):
                        if self.createdFile:
                                return self.partNo
                        else:
                                return self.partNo - 1
                        
        def generateProps(item):

                def generateConfigurations(outFile):
                        configs = set()
                        for no in range(len(configurations)):
                                outFile.cwrite("\r\nIndividual: c:" + cveID + "-C" + str(no) + "\r\tTypes: \r\t\t" + "Configuration\r\tFacts:")
                                configs.add(outFile.getOntoName() + ":" + cveID + "-C" + str(no))
                                first = True
                                for cpe in configurations[no]:
                                        if first:
                                                first = False
                                        else:
                                                outFile.cwrite(",")
                                        if cpe["vulnerable"]:
                                                outFile.cwrite("\r\t\t\tvulnerableCPE cpe:<" + convert_fs_to_compressed_uri(cpe["cpeURI"]) + ">")
                                        else:
                                                outFile.cwrite("\r\t\t\tnonVulnerableCPE cpe:<" + convert_fs_to_compressed_uri(cpe["cpeURI"]) + ">")
                        outFile.cflush()
                        return configs
                #End of generateConfigurations()

                def findNode(node):
                        #The node contains children or cpe_match.

                        def findMatch(match):
                                #match is a def_cpe_match from nvd_cpematch_feed_json_1.0.schema.
                                #Every def_cpe_match contains at least cpe23Uri that is a match pattern (CPE Match).
                                #Other keys are optional.
                                #The key cpe_name of match must not be included in CVE Feeds (nvd_cve_feed_json_1.1.schema).
                                #The CVE feed is expected to be formed in accordance with the above schema.
                                #cpe_name must not participate in the match keys of the CVE Feed.
                                matchKeys = sorted(match)
                                matchKeys.remove("vulnerable")
                                if "cpe_name" in matchKeys: matchKeys.remove("cpe_name")
                                #Construct the key for cpeFeeds from m keys and their values in sorted order
                                key = ""
                                for k in matchKeys:
                                        key += k + match[k]
                               
                                if key not in cpeFeeds:
                                        log.write("Bad CPE:" + match["cpe23Uri"] + "\n")
                                        return list()
                                configs = list()
                                for cpeURI in cpeFeeds[key]:
                                        configs.append([{"vulnerable":match["vulnerable"], "cpeURI":cpeURI}])
                                        
                                #Return a list of lists of dictionaries {"vulnerable":True/False, "cpeURIs":cpe} corresponding to that CPE match.
                                #Every configuration is a list of CPE URIs vulnerable or not.
                                #It is possible the list to be empty, because some CPE matchs in CPE Feeds have empty cpe lists.
                                return configs
                        #End of findMatch(match)
                        
                        operands = list()
                        if "cpe_match" in node:
                                #All lists of cpes for every "cpe_match" element are appended to operands.
                                for match in node["cpe_match"]:
                                        o = findMatch(match)
                                        #Empty lists are not appended.
                                        if len(o) > 0: operands.append(o)
                        if "children" in node:
                                #All lists of cpes for every "children" element are appended to operands.
                                for subNode in node["children"]:
                                        o = findNode(subNode)
                                        #Empty lists are not appended.
                                        if len(o) > 0: operands.append(o)
                        configs = list()
                        #Operator OR means that every configuration in configs is independent.
                        if node["operator"] == "OR":
                                for operand in operands:
                                        configs.extend(operand)
                        #Operator AND means that all operand configurations have to be combined in configurations (Cartesian product).
                        elif node["operator"] == "AND":
                                if len(operands) < 2:
                                        for operand in operands:
                                                configs.extend(operand)
                                else:
                                        combined = list()
                                        for config0 in operands[0]:
                                                for config1 in operands[1]:
                                                        c = config0.copy()
                                                        c.extend(config1)
                                                        combined.append(c)
                                        for config in combined:
                                                c = config.copy()
                                                for i in range(2, len(operands)):
                                                        for configi in operands[i]:
                                                                c.extend(configi)
                                                configs.append(c)
                                        if len(operands) == 2: configs = combined
                        #If negated the node this means that all vulnerable values have to be inverted.
                        if  "negate" in node and node["negate"]:
                                for config in configs:
                                        for cpe in config:
                                                cpe["vulnerable"] = not cpe["vulnerable"]
                        return configs
                #End of findNode(node)

                def generateAffects():
                        cveID = item["cve"]["CVE_data_meta"]["ID"]
                        for vd in item["cve"]["affects"]["vendor"]:
                                vendorID = cveID + "-" + vd["vendor_name"]
                                outFile.write("\r\nIndividual: " + vendorID + "\r\tTypes: \r\t\t" + "Vendor\r\tFacts:\r\t\tvendor_name \"" + codeString(vd["vendor_name"]) + "\"")
                                for p in vd["product"]:
                                        productID = vendor_name + "-" + p["product_name"]
                                        outFile.write("\r\t\tproduct " + productID)
                                for p in vd["product"]:
                                        productID = vendor_name + "-" + p["product_name"]
                                        outFile.write("\r\nIndividual: " + productID + "\r\tTypes: \r\t\t" + "Product\r\tFacts:\r\t\tproduct_name \"" + codeString(p["product_name"]) + "\"")
                                        for v in p["version"]:
                                                versionID = product_name + "-" + v["version_value"]
                                                outFile.write("\r\t\tversion " + versionID)
                                        for v in p["version"]:
                                                versionID = product_name + "-" + v["version_value"]
                                                outFile.write("\r\nIndividual: " + versionID + "\r\tTypes: \r\t\t" + "Version\r\tFacts:\r\t\tversion_value " + codeString(v["version_value"]) + \
                                                              "\"\r\t\tversion_affected \"" + codeString(v["version_affected"]) + "\"")
                #End of generateAffects()
           
                factsOut = False
                
                def writeFacts(txt):
                        nonlocal factsOut
                        if factsOut:
                                outFile.write(",\r")
                        else:
                                outFile.write("\tFacts:\r")
                                factsOut = True
                        outFile.write(txt)
                #End of writeFacts(txt)
                        
                if "publishedDate" in item:
                        outFile.write("\tFacts:\r\t\tpublishedDate \"" + item["publishedDate"] + "\"^^xsd:dateTime")
                        factsOut = True
                if "lastModifiedDate" in item:
                        writeFacts("\t\tlastModifiedDate \"" + item["lastModifiedDate"] + "\"^^xsd:dateTime")
                        
                for d in item["cve"]["problemtype"]["problemtype_data"]:
                        for e in d["description"]:
                                cwe = e["value"]
                                writeFacts("\t\tcwe cwe:" + cwe)

                cveID = item["cve"]["CVE_data_meta"]["ID"]
                if "affects" in item:
                        for vd in item["cve"]["affects"]["vendor"]:
                                writeFacts("\t\tvendor " + cveID + "-" + vd["vendor_name"])

                configurations = list()
                for node in item["configurations"]["nodes"]:
                        configurations.extend(findNode(node))
                if len(configurations) > 0:
                        for c in generateConfigurations(outFile):
                                writeFacts("\t\tconfiguration " + c)

                if "impact" in item:
                        if "baseMetricV2" in item["impact"]:
                                writeFacts("\t\tbaseMetricV2 cve:" + cveID + "-CVSSV2")
                        if "baseMetricV3" in item["impact"]:
                                writeFacts("\t\tbaseMetricV3 cve:" + cveID + "-CVSSV3")

                if "impact" in item and "baseMetricV2" in item["impact"]:
                        outFile.write("\r\nIndividual: cve:" + cveID + "-CVSSV2" + "\r\tTypes: \r\t\t" + "CVSSV20\r")
                        baseMetricV2 = item["impact"]["baseMetricV2"]
                        if "cvssV2" in baseMetricV2:
                                cvssV2 = baseMetricV2["cvssV2"]
                                outFile.write("\r\tFacts:\r\t\tbaseScoreV2 " + str(cvssV2["baseScore"]))
                                if "accessVector" in cvssV2: outFile.write(",\r\t\taccessVector \"" + cvssV2["accessVector"] + "\"")
                                if "accessComplexity" in cvssV2: outFile.write(",\r\t\taccessComplexity \"" + cvssV2["accessComplexity"] + "\"")
                                if "authentication" in cvssV2: outFile.write(",\r\t\tauthentication \"" + cvssV2["authentication"] + "\"")
                                if "confidentialityImpact" in cvssV2: outFile.write(",\r\t\tconfidentialityImpactV2 \"" + cvssV2["authentication"] + "\"")
                                if "integrityImpact" in cvssV2: outFile.write(",\r\t\tintegrityImpactV2 \"" + cvssV2["integrityImpact"] + "\"")
                                if "availabilityImpact" in cvssV2: outFile.write(",\r\t\tavailabilityImpactV2 \"" + cvssV2["availabilityImpact"] + "\"")
                                if "exploitability" in cvssV2: outFile.write(",\r\t\texploitability \"" + cvssV2["exploitability"] + "\"")
                                if "remediationLevel" in cvssV2: outFile.write(",\r\t\tremediationLevel \"" + cvssV2["remediationLevel"] + "\"")
                                if "temporalScore" in cvssV2: outFile.write(",\r\t\ttemporalScoreV2 " + str(cvssV2["temporalScore"]))
                                if "collateralDamagePotential" in cvssV2: outFile.write(",\r\t\tcollateralDamagePotential \"" + cvssV2["collateralDamagePotential"] + "\"")
                                if "targetDistribution" in cvssV2: outFile.write(",\r\t\ttargetDistribution \"" + cvssV2["targetDistribution"] + "\"")
                                if "confidentialityRequirement" in cvssV2: outFile.write(",\r\t\tconfidentialityRequirement \"" + cvssV2["confidentialityRequirement"] + "\"")
                                if "integrityRequirement" in cvssV2: outFile.write(",\r\t\tintegrityRequirement \"" + cvssV2["integrityRequirement"] + "\"")
                                if "availabilityRequirement" in cvssV2: outFile.write(",\r\t\tavailabilityRequirement \"" + cvssV2["availabilityRequirement"] + "\"")
                                if "environmentalScore" in cvssV2: outFile.write(",\r\t\tenvironmentalScore " + str(cvssV2["environmentalScore"]))
                        if "severity" in baseMetricV2: outFile.write(",\r\t\tseverity \"" + codeString(baseMetricV2["severity"]) + "\"")
                        if "exploitabilityScore" in baseMetricV2: outFile.write(",\r\t\texploitabilityScore " + str(baseMetricV2["exploitabilityScore"]))
                        if "impactScore" in baseMetricV2: outFile.write(",\r\t\timpactScore " + str(baseMetricV2["impactScore"]))
                        if "acInsufInfo" in baseMetricV2: outFile.write(",\r\t\tacInsufInfo " + str(baseMetricV2["acInsufInfo"]))
                        if "obtainAllPrivilege" in baseMetricV2: outFile.write(",\r\t\tobtainAllPrivilege " + str(baseMetricV2["obtainAllPrivilege"]))
                        if "obtainUserPrivilege" in baseMetricV2: outFile.write(",\r\t\tobtainUserPrivilege " + str(baseMetricV2["obtainUserPrivilege"]))
                        if "obtainOtherPrivilege" in baseMetricV2: outFile.write(",\r\t\tobtainOtherPrivilege " + str(baseMetricV2["obtainOtherPrivilege"]))
                        if "userInteractionRequired" in baseMetricV2: outFile.write(",\r\t\tuserInteractionRequired " + str(baseMetricV2["userInteractionRequired"]))
                                
                if "impact" in item and "baseMetricV3" in item["impact"]:
                        outFile.write("\r\nIndividual: cve:" + cveID + "-CVSSV3" + "\r\tTypes: \r\t\t" + "CVSSV3X\r")
                        baseMetricV3 = item["impact"]["baseMetricV3"]
                        if "cvssV3" in baseMetricV3:
                                cvssV3 = baseMetricV3["cvssV3"]
                                outFile.write("\r\tFacts:\r\t\tbaseScore " + str(cvssV3["baseScore"]))
                                if "attackVector" in cvssV3: outFile.write(",\r\t\tattackVector \"" + cvssV3["attackVector"] + "\"")
                                if "attackComplexity" in cvssV3: outFile.write(",\r\t\tattackComplexity \"" + cvssV3["attackComplexity"] + "\"")
                                if "privilegesRequired" in cvssV3: outFile.write(",\r\t\tprivilegesRequired \"" + cvssV3["privilegesRequired"] + "\"")
                                if "userInteraction" in cvssV3: outFile.write(",\r\t\tuserInteraction \"" + cvssV3["userInteraction"] + "\"")
                                if "scope" in cvssV3: outFile.write(",\r\t\tscope \"" + cvssV3["scope"] + "\"")
                                if "confidentialityImpact" in cvssV3: outFile.write(",\r\t\tconfidentialityImpact \"" + cvssV3["confidentialityImpact"] + "\"")
                                if "integrityImpact" in cvssV3: outFile.write(",\r\t\tintegrityImpact \"" + cvssV3["integrityImpact"] + "\"")
                                if "availabilityImpact" in cvssV3: outFile.write(",\r\t\tavailabilityImpact \"" + cvssV3["availabilityImpact"] + "\"")
                                if "baseSeverity" in cvssV3: outFile.write(",\r\t\tbaseSeverity \"" + cvssV3["baseSeverity"] + "\"")
                                if "exploitCodeMaturity" in cvssV3: outFile.write(",\r\t\texploitCodeMaturity \"" + cvssV3["exploitCodeMaturity"] + "\"")
                                if "remediationLevel" in cvssV3: outFile.write(",\r\t\tremediationLevel \"" + cvssV3["remediationLevel"] + "\"")
                                if "reportConfidence" in cvssV3: outFile.write(",\r\t\treportConfidence \"" + cvssV3["reportConfidence"] + "\"")
                                if "temporalScore" in cvssV3: outFile.write(",\r\t\ttemporalScoreV2 \"" + str(cvssV3["temporalScore"]))
                                if "temporalSeverity" in cvssV3: outFile.write(",\r\t\ttemporalSeverity \"" + cvssV3["temporalSeverity"] + "\"")
                                if "confidentialityRequirement" in cvssV3: outFile.write(",\r\t\tconfidentialityRequirement \"" + cvssV3["confidentialityRequirement"] + "\"")
                                if "integrityRequirement" in cvssV3: outFile.write(",\r\t\tintegrityRequirement \"" + cvssV3["integrityRequirement"] + "\"")
                                if "availabilityRequirement" in cvssV3: outFile.write(",\r\t\tavailabilityRequirement \"" + cvssV3["availabilityRequirement"] + "\"")
                                if "modifiedAttackVector" in cvssV3: outFile.write(",\r\t\tmodifiedAttackVector \"" + cvssV3["modifiedAttackVector"] + "\"")
                                if "modifiedAttackComplexity" in cvssV3: outFile.write(",\r\t\tmodifiedAttackComplexity \"" + cvssV3["modifiedAttackComplexity"] + "\"")
                                if "modifiedPrivilegesRequired" in cvssV3: outFile.write(",\r\t\tmodifiedPrivilegesRequired \"" + cvssV3["modifiedPrivilegesRequired"] + "\"")
                                if "modifiedUserInteraction" in cvssV3: outFile.write(",\r\t\tmodifiedUserInteraction \"" + cvssV3["modifiedUserInteraction"] + "\"")
                                if "modifiedScope" in cvssV3: outFile.write(",\r\t\tmodifiedScope \"" + cvssV3["modifiedScope"] + "\"")
                                if "modifiedConfidentialityImpact" in cvssV3: outFile.write(",\r\t\tmodifiedConfidentialityImpact \"" + cvssV3["modifiedConfidentialityImpact"] + "\"")
                                if "modifiedIntegrityImpact" in cvssV3: outFile.write(",\r\t\tmodifiedIntegrityImpact \"" + cvssV3["modifiedIntegrityImpact"] + "\"")
                                if "modifiedAvailabilityImpact" in cvssV3: outFile.write(",\r\t\tmodifiedAvailabilityImpact \"" + cvssV3["modifiedAvailabilityImpact"] + "\"")
                                if "environmentalScore" in cvssV3: outFile.write(",\r\t\tenvironmentalScore " + str(cvssV3["environmentalScore"]))
                                if "environmentalSeverity" in cvssV3: outFile.write(",\r\t\tenvironmentalSeverity \"" + cvssV3["environmentalSeverity"] + "\"")
                                
                        if "exploitabilityScore" in baseMetricV3: outFile.write(",\r\t\texploitabilityScore " + str(baseMetricV3["exploitabilityScore"]))
                        if "impactScore" in baseMetricV3: outFile.write(",\r\t\timpactScore " + str(baseMetricV3["impactScore"]))

                if "affects" in item: generateAffects()
        #End of generateProps(item)
        
        def genFeedOntology(feedName, parts):
                with open("results/o" + feedName + ".owl", "w", encoding="utf-8") as oFile:
                        oFile.write(head)
                        oFile.write("\r\nOntology: <http://www.semanticweb.org/cht_c/o" + feedName + ">")
                        for p in range(parts + 1):
                                oFile.write("\r\nImport: <http://www.semanticweb.org/cht_c/o" + feedName + str(p) + ">")
        #End genFeedOntology
        
        feedName = inQueue.get()
        while feedName != "DONE":
                with open("results/o" + feedName + ".log", "w", encoding="utf-8") as log:
                        log.write(feedName + "\n")
                        with open("data/nvdcve-1.1-" + feedName + ".json", "r", encoding="utf-8") as inFile:
                                d = json.loads(inFile.read())
                        count = 0
                        outFile = BF(feedName)
                        isModified = False
                        if modified is None:
                                modified =  set()
                                isModified = True
                        for item in d["CVE_Items"]:
                                cveID = item["cve"]["CVE_data_meta"]["ID"]
                                print(cveID)
                                if isModified:
                                        modified.add(cveID)
                                        if onlyModifiedCVEs: continue
                                elif cveID in modified: continue
                                log.write(cveID + "\n")
                                outFile.write("\r\nIndividual: cve:" + cveID + "\r\n\tAnnotations:\r\t\tASSIGNER \"" + item["cve"]["CVE_data_meta"]["ASSIGNER"] + "\"@en")
                                if "STATE" in item["cve"]["CVE_data_meta"].keys():
                                        outFile.write(",\r\t\tSTATE \"" + item["cve"]["CVE_data_meta"]["STATE"] + "\"@en")

                                for rd in item["cve"]["references"]["reference_data"]:
                                        outFile.write(",\r\t\treference \"" + rd["url"])
                                        if "name" in rd:
                                                name = rd["name"]
                                                if "\\" in name: name = name.replace("\\", "\\\\\\\\")
                                                if "\"" in name: name = name.replace("\"", "\\\"")
                                                outFile.write("\r" + name)
                                        if "refsource" in rd: outFile.write("\r" + rd["refsource"])
                                        if "tags" in rd:
                                                firstTag = True
                                                for t in rd["tags"]:
                                                        if firstTag:
                                                                outFile.write("\r")
                                                                firstTag = False      
                                                        else:
                                                                outFile.write(" ")
                                                        outFile.write(t)
                                        outFile.write("\"@en")
                                
                                for dd in item["cve"]["description"]["description_data"]:
                                        value = dd["value"]
                                        if "\\" in value: value = value.replace("\\", "\\\\\\\\")
                                        if "\"" in value: value = value.replace("\"", "\\\"")
                                        outFile.write(",\r\t\tdescription \"" + value + "\"@" + dd["lang"])
                                
                                outFile.write("\r\n\tTypes:\r\t\tCVE\r\n")
                                generateProps(item)
                                outFile.flush()
                                count += 1
                        outFile.close()
                        if isModified:
                                if onlyModifiedCVEs:
                                        resultQueue.put(modified)
                                else:
                                        resultQueue.put(count)
                                        resultQueue.put(modified)
                        else:
                                resultQueue.put(count)
                        genFeedOntology(feedName, outFile.parts())
                        feedName = inQueue.get()
                resultQueue.put("DONE")
#End processFeed(inQueue, resultQueue, cpeFeeds, modified = None, onlyModifiedCVEs = False)

def main(download, feeds):
        
        def genOntology():
                with open("results/cve.owl", "w", encoding="utf-8") as oFile:
                        oFile.write(head)
                        oFile.write("\r\nOntology: <http://www.semanticweb.org/cht_c/cve>")
                        for f in feeds:
                                oFile.write("\r\nImport: <http://www.semanticweb.org/cht_c/o" + f + ">")
        #End genOntology

        def downloadNVD():
                def is_downloaded(name):
                        with urllib.request.urlopen("https://nvd.nist.gov/feeds/json/cve/1.1/" + name) as response:
                                contents = response.read()
                                lines = contents.decode("utf-8").split("\r")
                                newDate = datetime.fromisoformat(lines[0].replace("lastModifiedDate:", ""))

                        fileName = "data/" + name
                        if not os.path.exists(fileName):
                                with open(fileName, 'wb') as outFile:
                                        outFile.write(contents)
                                return False
                        
                        with open(fileName, 'r', encoding="utf-8") as inFile:
                                oldDate = datetime.fromisoformat(inFile.readline().rstrip("\n").replace("lastModifiedDate:", ""))
                        if newDate > oldDate:
                                with open(fileName, 'wb') as outFile:
                                        outFile.write(contents)
                                        return False
                        return True
                #End of is_downloaded(name)

                def download(url, fileName):
                        print(url)
                        with urllib.request.urlopen(url) as response:
                                contents = response.read()
                                with open(fileName, mode='wb') as out_file:
                                        out_file.write(contents)
                        with zipfile.ZipFile(fileName, 'r') as zip_ref:
                            zip_ref.extractall(path="data")
                #End of download(url, filename)
                
                for year in range(2002, datetime.now().year + 1):
                        baseName = "nvdcve-1.1-" + str(year)
                        if is_downloaded(baseName + ".meta"):
                                print("Downloaded: " + "https://nvd.nist.gov/feeds/json/cve/1.1/" + baseName + ".json.zip")
                                continue
                        baseName = baseName + ".json.zip"
                        download("https://nvd.nist.gov/feeds/json/cve/1.1/" + baseName, "data/" + baseName)

                download("https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-modified.json.zip", "data/nvdcve-1.1-modified.json.zip")
                download("https://nvd.nist.gov/feeds/json/cpematch/1.0/nvdcpematch-1.0.json.zip", "data/nvdcpematch-1.0.json.zip")
        #End of downloadNVD()
                    
        print("NVD Ontology Generator, Version 1.4")
        start = datetime.now()
        print(start)
        genOntology()
        if download:
                print("Download NVD")
                downloadNVD()
        
        shell_fn = "shell.owl"
        with open("shell.owl", mode='r', encoding='utf-8') as in_file, open("results/nvd.owl", mode='w', encoding='utf-8') as out_file:
                shell = in_file.read()
                shell = shell.replace("XXXX-XX-XXTXX:XX:XX-XX:XX", str(datetime.now()))
                out_file.write(shell)
        
        print("Load CPE Feeds")       
        with open("data/nvdcpematch-1.0.json", "r", encoding="utf-8") as inFile:
                cpeFeed = json.loads(inFile.read())
        #cpeFeeds is a dictionary. cpe23Uri represents a CPE match pattern. cpe_name is a list of CPEs from the CPE Dictionary.
        #The keys are formed by concatanating all keys (without cpe_name) and their values in def_cpe_match.
        #The value is the list of all CPE names found in cpe_name.
        #CPE feeds is expected to be formed in accordance with the schema: cpe23Uri and cpe_name are required. 
        cpeFeeds = dict()
        for match in cpeFeed["matches"]:
                #Form the key.
                keys = sorted(match)
                keys.remove("cpe_name")
                key = ""
                for k in keys:
                        key += k + match[k]
                #Form the value for the key appending all CPEs from this match.
                cpes = list()
                for e in match["cpe_name"]:
                        cpes.append(e["cpe23Uri"])
                if len(cpes) > 0: cpeFeeds[key] = cpes
        cpeFeed = None
        
        inQueue = Queue()
        resultQueue = Queue()
                
        print("Load json dictionaries:")
        counts = 0
        count = 0
        processModified = "modified" in feeds
        if processModified: print("Modified")
        p = Process(name = "Modified", target = processFeed, args = (inQueue, resultQueue, cpeFeeds, None, not processModified))
        p.start()
        inQueue.put("modified")
        inQueue.put("DONE")
        if processModified: count = resultQueue.get()
        modified = resultQueue.get()
        resultQueue.get() #get DONE
        p.join()

        counts += count      
        try:
                feeds.remove("modified")
        except ValueError:
                pass
        nf = len(feeds)
        if nf > 0:
                processes = []
                np = cpu_count()
                np = nf if nf < np else np
                for i in range(np):
                        p = Process(name = "Process " + str(i), target = processFeed, args=(inQueue, resultQueue, cpeFeeds, modified))
                        processes.append(p)
                        p.start() 
                
                for feed in feeds:
                        if feed == "modified": continue
                        inQueue.put(feed)
                        print(feed)
                for i in range(np):
                        inQueue.put("DONE")

                print("Get from the queue the number of processed CVEs.")
                count = np
                while count > 0:
                        val = resultQueue.get()
                        if val  == "DONE":
                                count -= 1
                        else:
                                counts += val
                print("Join the processes.")
                for i in range(np):
                        processes[i].join()
        print("3")        
        print(f"CVEs: {counts}")                                
        print("Loaded all dictionaries")

        end = datetime.now()
        print(end)
        print(f"Elapsed: {end - start}")

if __name__ == "__main__":
        feeds = ["modified"]
        feeds.extend(map(str, range(2002, datetime.now().year + 1)))
        parser = argparse.ArgumentParser()
        parser.add_argument('-d', '--download', action="store_true", help='download input from the Web')
        parser.add_argument('-f', '--feed', action="append", default=[], choices=feeds, help='specify feeds to process')
        args = parser.parse_args()
        if args.feed == []:
                main(args.download, feeds)
        else:
                sFeeds = set(args.feed)
                for f in sFeeds:
                        if f.lower() not in feeds:
                                print("No such a feed: " + f)
                                quit()
                main(args.download, list(sFeeds))
