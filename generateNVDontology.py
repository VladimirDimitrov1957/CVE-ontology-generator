"""NVD ontology generator.

The generator downloads the current version of NVD from NIST site and then generates OWL Turtle syntax ontology.
The dictionary is downloaded as .zip file and then it is unzipped.
The ontology is generated with the file name "cve.ttl".
All operations and files are placed in the current directory.
"""

import urllib.request, os, zipfile, json, jsonschema, shutil, re, sys, argparse
from jsonschema import validate
from datetime import datetime
from dateutil.parser import isoparse
from multiprocessing import Process, Queue, Manager, cpu_count, freeze_support
from cpe import *

def codeString(s):
        temp = s.replace("\\", "\\\\")
        return temp.replace('"', "\\\"")

def processFeed(inQueue, resultQueue, cpeFeeds, modified = None, onlyModifiedCVEs = False):

        def generateProps(item):

                def getLinksToConfigurations():
                        configs = set()
                        for no in range(len(configurations)):
                                iri = cveID + "-C" + str(no)      
                                configs.add(iri) 
                        return configs
                #End of getLinksToConfigurations()

                def generateConfigurationObjects(outFile):
                        for no in range(len(configurations)):
                                iri = cveID + "-C" + str(no)
                                outFile.write("\n\n### " + iri + "\n:" + iri + '\n\trdf:type owl:NamedIndividual ;\n\trdf:type :Configuration')        
                                for cpe in configurations[no]:
                                        if cpe["vulnerable"]:
                                                outFile.write(" ;\n\t:vulnerableCPE <" + convert_fs_to_compressed_uri(cpe["cpeURI"]) + ">")
                                        else:
                                                outFile.write(" ;\n\t:nonVulnerableCPE <" + convert_fs_to_compressed_uri(cpe["cpeURI"]) + ">")
                                outFile.write(" ;\n\trdf:type owl:Thing .")  
                #End of generateConfigurationObjects()

                def findNode(node):
                        #The node contains children or cpe_match.

                        def findMatch(match):
                                #match is a def_cpe_match from nvd_cpematch_feed_json_1.0.schema.
                                #Every def_cpe_match contains at least cpe23Uri that is a match pattern (CPE Match).
                                #Other keys are optional.
                                #The key cpe_name of match must not be included in CVE Feeds (nvd_cve_feed_json_1.1.schema).
                                #The CVE feed is expected to be formed in accordance with the above schema.
                                #cpe_name must not participate in the match keys of the CVE Feed.
                                matchKeys = sorted(match)
                                matchKeys.remove("vulnerable")
                                if "cpe_name" in matchKeys: matchKeys.remove("cpe_name")
                                #Construct the key for cpeFeeds from m keys and their values in sorted order
                                key = ""
                                for k in matchKeys:
                                        key += k + match[k]
                               
                                if key not in cpeFeeds:
                                        log.write("Bad CPE:" + match["cpe23Uri"] + "\n")
                                        return list()
                                configs = list()
                                for cpeURI in cpeFeeds[key]:
                                        configs.append([{"vulnerable":match["vulnerable"], "cpeURI":cpeURI}])
                                        
                                #Return a list of lists of dictionaries {"vulnerable":True/False, "cpeURIs":cpe} corresponding to that CPE match.
                                #Every configuration is a list of CPE URIs vulnerable or not.
                                #It is possible the list to be empty, because some CPE matchs in CPE Feeds have empty cpe lists.
                                return configs
                        #End of findMatch(match)
                        
                        operands = list()
                        if "cpe_match" in node:
                                #All lists of cpes for every "cpe_match" element are appended to operands.
                                for match in node["cpe_match"]:
                                        o = findMatch(match)
                                        #Empty lists are not appended.
                                        if len(o) > 0: operands.append(o)
                        if "children" in node:
                                #All lists of cpes for every "children" element are appended to operands.
                                for subNode in node["children"]:
                                        o = findNode(subNode)
                                        #Empty lists are not appended.
                                        if len(o) > 0: operands.append(o)
                        configs = list()
                        #Operator OR means that every configuration in configs is independent.
                        if node["operator"] == "OR":
                                for operand in operands:
                                        configs.extend(operand)
                        #Operator AND means that all operand configurations have to be combined in configurations (Cartesian product).
                        elif node["operator"] == "AND":
                                if len(operands) < 2:
                                        for operand in operands:
                                                configs.extend(operand)
                                else:
                                        combined = list()
                                        for config0 in operands[0]:
                                                for config1 in operands[1]:
                                                        c = config0.copy()
                                                        c.extend(config1)
                                                        combined.append(c)
                                        for config in combined:
                                                c = config.copy()
                                                for i in range(2, len(operands)):
                                                        for configi in operands[i]:
                                                                c.extend(configi)
                                                configs.append(c)
                                        if len(operands) == 2: configs = combined
                        #If negated the node this means that all vulnerable values have to be inverted.
                        if  "negate" in node and node["negate"]:
                                for config in configs:
                                        for cpe in config:
                                                cpe["vulnerable"] = not cpe["vulnerable"]
                        return configs
                #End of findNode(node)

                def generateAffects():
                        cveID = item["cve"]["CVE_data_meta"]["ID"]
                        for vd in item["cve"]["affects"]["vendor"]:
                                vendorID = cveID + "-" + vd["vendor_name"]
                                outFile.write("\n\n### " + vendorID + "\n:" + vendorID + '\n\trdf:type owl:NamedIndividual ;\n\t:Vendor ;\n\t:vendor_name "' + codeString(vd["vendor_name"]) + '"@en')
                                for p in vd["product"]:
                                        productID = vendor_name + "-" + p["product_name"]
                                        outFile.write(" ;\n\t:product :" + productID)
                                outFile.cwrite(" ;\n\trdf:type owl:Thing .")
                                for p in vd["product"]:
                                        productID = vendor_name + "-" + p["product_name"]
                                        outFile.write("\n\n### " + productID + "\n:" + productID + '\n\trdf:type owl:NamedIndividual ;\n\t:Product ;\n\t:product_name "' + codeString(vd["product_name"]) + '"@n')
                                        for v in p["version"]:
                                                versionID = product_name + "-" + v["version_value"]
                                                outFile.write(" ;\n\t:version :" + versionID)
                                        outFile.cwrite(" ;\n\trdf:type owl:Thing .")
                                        for v in p["version"]:
                                                versionID = product_name + "-" + v["version_value"]
                                                outFile.write("\n\n### " + versionID + "\n:" + versionID + '\n\trdf:type owl:NamedIndividual ;\n\t:Version ;\n\t:version_value "' + codeString(vd["tversion_value"]) + '"@en' \
                                                              ' ;\n\t:version_affected "' + codeString(v["version_affected"]) + '"@en ;\n\trdf:type owl:Thing .')
                #End of generateAffects()

                def checkDT(dt):
                        return isoparse(dt).isoformat()
                        
                if "publishedDate" in item: outFile.write(' ;\n\t:publishedDate "' + checkDT(item["publishedDate"]) + '"^^xsd:dateTime')
                if "lastModifiedDate" in item: outFile.write(' ;\n\t:lastModifiedDate "' + checkDT(item["lastModifiedDate"]) + '"^^xsd:dateTime')
                
                for d in item["cve"]["problemtype"]["problemtype_data"]:
                        for e in d["description"]: outFile.write(" ;\n\t:cwe cwe:" + e["value"])
                        
                cveID = item["cve"]["CVE_data_meta"]["ID"]
                if "affects" in item:
                        for vd in item["cve"]["affects"]["vendor"]: outFile.write(" ;\n\t:vendor " + cveID + "-" + vd["vendor_name"])

                configurations = list()
                for node in item["configurations"]["nodes"]:
                        configurations.extend(findNode(node))
                if len(configurations) > 0:
                        for c in getLinksToConfigurations(): outFile.write(" ;\n\t:configuration :" + c)

                if "impact" in item:
                        if "baseMetricV2" in item["impact"]: outFile.write(" ;\n\t:baseMetricV2 :" + cveID + "-CVSSV2")
                        if "baseMetricV3" in item["impact"]: outFile.write(" ;\n\t:baseMetricV3 :" + cveID + "-CVSSV3")

                outFile.write(" ;\n\trdf:type owl:Thing .")

                if len(configurations) > 0:
                        generateConfigurationObjects(outFile)
                
                if "impact" in item and "baseMetricV2" in item["impact"]:
                        iri = cveID + '-CVSSV2'
                        outFile.write("\n\n### " + iri + "\n:" + iri + '\n\trdf:type owl:NamedIndividual ;\n\trdf:type :CVSSV20')
                        baseMetricV2 = item["impact"]["baseMetricV2"]
                        if "cvssV2" in baseMetricV2:
                                cvssV2 = baseMetricV2["cvssV2"]
                                outFile.write(" ;\n\t:baseScore " + str(cvssV2["baseScore"]))
                                if "accessVector" in cvssV2: outFile.write(' ;\n\t:accessVector "' + cvssV2["accessVector"] + '"')
                                if "accessComplexity" in cvssV2: outFile.write(' ;\n\t:accessComplexity "' + cvssV2["accessComplexity"] + '"')
                                if "authentication" in cvssV2: outFile.write(' ;\n\t:authentication "' + cvssV2["authentication"] + '"')
                                if "confidentialityImpact" in cvssV2: outFile.write(' ;\n\t:confidentialityImpactV2 "' + cvssV2["confidentialityImpact"] + '"')
                                if "integrityImpact" in cvssV2: outFile.write(' ;\n\t:integrityImpactV2 "' + cvssV2["integrityImpact"] + '"')
                                if "availabilityImpact" in cvssV2: outFile.write(' ;\n\t:availabilityImpactV2 "' + cvssV2["availabilityImpact"] + '"')
                                if "exploitability" in cvssV2: outFile.write(' ;\n\t:exploitability "' + cvssV2["exploitability"] + '"')
                                if "remediationLevel" in cvssV2: outFile.write(' ;\n\t:remediationLevel "' + cvssV2["remediationLevel"] + '"')
                                if "temporalScore" in cvssV2: outFile.write(" ;\n\t:temporalScoreV2 " + str(cvssV2["temporalScore"]))
                                if "collateralDamagePotential" in cvssV2: outFile.write(' ;\n\t:collateralDamagePotential "' + cvssV2["collateralDamagePotential"] + '"')
                                if "targetDistribution" in cvssV2: outFile.write(' ;\n\t:targetDistribution "' + cvssV2["targetDistribution"] + '"')
                                if "confidentialityRequirement" in cvssV2: outFile.write(' ;\n\t:confidentialityRequirement "' + cvssV2["confidentialityRequirement"] + '"')
                                if "integrityRequirement" in cvssV2: outFile.write(' ;\n\t:integrityRequirement "' + cvssV2["integrityRequirement"] + '"')
                                if "availabilityRequirement" in cvssV2: outFile.write(' ;\n\t:availabilityRequirement "' + cvssV2["availabilityRequirement"] + '"')
                                if "environmentalScore" in cvssV2: outFile.write(' ;\n\t:environmentalScoreV2 "' + str(cvssV2["environmentalScore"]))
                        if "exploitabilityScore" in baseMetricV2: outFile.write(" ;\n\t:exploitabilityScore " + str(baseMetricV2["exploitabilityScore"]))
                        if "impactScore" in baseMetricV2: outFile.write(" ;\n\t:impactScore " + str(baseMetricV2["impactScore"]))
                        if "acInsufInfo" in baseMetricV2: outFile.write(' ;\n\t:acInsufInfo "' + str(baseMetricV2["acInsufInfo"]).lower() + '"^^xsd:boolean')
                        if "obtainAllPrivilege" in baseMetricV2: outFile.write(' ;\n\t:obtainAllPrivilege "' + str(baseMetricV2["obtainAllPrivilege"]).lower() + '"^^xsd:boolean')
                        if "obtainUserPrivilege" in baseMetricV2: outFile.write(' ;\n\t:obtainUserPrivilege "' + str(baseMetricV2["obtainUserPrivilege"]).lower() + '"^^xsd:boolean')
                        if "obtainOtherPrivilege" in baseMetricV2: outFile.write(' ;\n\t:obtainOtherPrivilege "' + str(baseMetricV2["obtainOtherPrivilege"]).lower() + '"^^xsd:boolean')
                        if "userInteractionRequired" in baseMetricV2: outFile.write(' ;\n\t:userInteractionRequired "' + str(baseMetricV2["userInteractionRequired"]).lower() + '"^^xsd:boolean')
                        outFile.write(" ;\n\trdf:type owl:Thing .")
                                
                if "impact" in item and "baseMetricV3" in item["impact"]:
                        iri = cveID + '-CVSSV3'
                        outFile.write("\n\n### " + iri + "\n:" + iri + '\n\trdf:type owl:NamedIndividual ;\n\trdf:type :CVSSV3X')
                        baseMetricV3 = item["impact"]["baseMetricV3"]
                        if "cvssV3" in baseMetricV3:
                                cvssV3 = baseMetricV3["cvssV3"]
                                outFile.write(" ;\n\t:baseScore " + str(cvssV3["baseScore"]))
                                if "attackVector" in cvssV3: outFile.write(' ;\n\t:attackVector "' + cvssV3["attackVector"] + '"')
                                if "attackComplexity" in cvssV3: outFile.write(' ;\n\t:attackComplexity "' + cvssV3["attackComplexity"] + '"')
                                if "privilegesRequired" in cvssV3: outFile.write(' ;\n\t:privilegesRequired "' + cvssV3["privilegesRequired"] + '"')
                                if "userInteraction" in cvssV3: outFile.write(' ;\n\t:userInteraction "' + cvssV3["userInteraction"] + '"')
                                if "scope" in cvssV3: outFile.write(' ;\n\t:scope "' + cvssV3["scope"] + '"')
                                if "confidentialityImpact" in cvssV3: outFile.write(' ;\n\t:confidentialityImpact "' + cvssV3["confidentialityImpact"] + '"')
                                if "integrityImpact" in cvssV3: outFile.write(' ;\n\t:integrityImpact "' + cvssV3["integrityImpact"] + '"')
                                if "availabilityImpact" in cvssV3: outFile.write(' ;\n\t:availabilityImpact "' + cvssV3["availabilityImpact"] + '"')
                                outFile.write(' ;\n\t:baseSeverity "' + cvssV3["baseSeverity"] + '"')
                                if "exploitCodeMaturity" in cvssV3: outFile.write(' ;\n\t:exploitCodeMaturity "' + cvssV3["exploitCodeMaturity"] + '"')
                                if "remediationLevel" in cvssV3: outFile.write(' ;\n\t:remediationLevel "' + cvssV3["remediationLevel"] + '"')
                                if "reportConfidence" in cvssV3: outFile.write(' ;\n\t:reportConfidence "' + cvssV3["reportConfidence"] + '"')
                                if "temporalScore" in cvssV3: outFile.write(' ;\n\t:temporalScore "' + str(cvssV3["temporalScore"]))
                                if "temporalSeverity" in cvssV3: outFile.write(' ;\n\t:severity "' + cvssV3["temporalSeverity"] + '"')
                                if "confidentialityRequirement" in cvssV3: outFile.write(' ;\n\t:confidentialityRequirement "' + cvssV3["confidentialityRequirement"] + '"')
                                if "integrityRequirement" in cvssV3: outFile.write(' ;\n\t:integrityRequirement "' + cvssV3["integrityRequirement"] + '"')
                                if "availabilityRequirement" in cvssV3: outFile.write(' ;\n\t:availabilityRequirement "' + cvssV3["availabilityRequirement"] + '"')
                                if "modifiedAttackVector" in cvssV3: outFile.write(' ;\n\t:modifiedAttackVector "' + cvssV3["modifiedAttackVector"] + '"')
                                if "modifiedAttackComplexity" in cvssV3: outFile.write(' ;\n\t:modifiedAttackComplexity "' + cvssV3["modifiedAttackComplexity"] + '"')
                                if "modifiedPrivilegesRequired" in cvssV3: outFile.write(' ;\n\t:modifiedPrivilegesRequired "' + cvssV3["modifiedPrivilegesRequired"] + '"')
                                if "modifiedUserInteraction" in cvssV3: outFile.write(' ;\n\t:modifiedUserInteraction "' + cvssV3["modifiedUserInteraction"] + '"')
                                if "modifiedScope" in cvssV3: outFile.write(' ;\n\t:modifiedScope "' + cvssV3["modifiedScope"] + '"')
                                if "modifiedConfidentialityImpact" in cvssV3: outFile.write(' ;\n\t:modifiedConfidentialityImpact "' + cvssV3["modifiedConfidentialityImpact"] + '"')
                                if "modifiedIntegrityImpact" in cvssV3: outFile.write(' ;\n\t:modifiedIntegrityImpact "' + cvssV3["modifiedIntegrityImpact"] + '"')
                                if "modifiedAvailabilityImpact" in cvssV3: outFile.write(' ;\n\t:modifiedAvailabilityImpact "' + cvssV3["modifiedAvailabilityImpact"] + '"')
                                if "environmentalScore" in cvssV3: outFile.write(" ;\n\t:environmentalScore " + str(cvssV3["environmentalScore"]))
                                if "environmentalSeverity" in cvssV3: outFile.write(' ;\n\t:environmentalSeverity "' + cvssV3["environmentalSeverity"] + '"')
                        if "exploitabilityScore" in baseMetricV3: outFile.write(" ;\n\t:exploitabilityScore " + str(baseMetricV3["exploitabilityScore"]))
                        if "impactScore" in baseMetricV3: outFile.write(" ;\n\t:impactScore " + str(baseMetricV3["impactScore"]))
                        outFile.write(" ;\n\trdf:type owl:Thing .")

                if "affects" in item: generateAffects()
                
        #End of generateProps(item)
        
        feedName = inQueue.get()
        while feedName != "DONE":
                with open("results/o" + feedName + ".log", "w", encoding="utf-8") as log:
                        log.write(feedName + "\n")
                        ifn = "data/nvdcve-1.1-" + feedName + ".json"
                        if not validateJSON(ifn, "data/nvd_cve_feed_json_1.1.schema", log):
                                feedName = inQueue.get()
                                continue
                        with open(ifn, "r", encoding="utf-8") as inFile:
                                d = json.loads(inFile.read())
                        count = 0
                        outFile = open("results/" + feedName + ".ttl", "w", encoding="utf-8")
                        with open("shell.ttl", "r", encoding="utf-8") as in_file:
                                shell = in_file.read()
                                shell = shell.replace(':CVE_data_timestamp ""@en ;', ':CVE_data_timestamp "' + d["CVE_data_timestamp"] + '"@en ;')
                                shell = shell.replace(':CVE_data_numberOfCVEs ""@en ;', ':CVE_data_numberOfCVEs "' + d['CVE_data_numberOfCVEs'] + '"@en ;')
                                outFile.write(shell.replace("<http://www.semanticweb.org/nvd>", "<http://www.semanticweb.org/nvd/" + feedName + ">"))

                        isModified = False
                        if modified is None:
                                modified =  set()
                                isModified = True
                        for item in d["CVE_Items"]:
                                cveID = item["cve"]["CVE_data_meta"]["ID"]
                                print(cveID)
                                if isModified:
                                        modified.add(cveID)
                                        if onlyModifiedCVEs: continue
                                elif cveID in modified: continue
                                log.write(cveID + "\n")
                                outFile.write("\n\n### " + cveID + "\n:" + cveID + '\n\trdf:type owl:NamedIndividual ;\n\t:ASSIGNER "')
                                assigner = "None"
                                if "ASSIGNER" in item["cve"]["CVE_data_meta"]: assigner = item["cve"]["CVE_data_meta"]["ASSIGNER"]
                                outFile.write(assigner + '"@en')
                                for rd in item["cve"]["references"]["reference_data"]:
                                        outFile.write(' ;\n\t:reference """' + rd["url"].replace("\\", "\\\\\\\\"))
                                        if "name" in rd: outFile.write("\n" + rd["name"].replace("\\", "\\\\\\\\"))
                                        if "refsource" in rd: outFile.write("\n" + rd["refsource"].replace("\\", "\\\\\\\\"))
                                        if "tags" in rd:
                                                firstTag = True
                                                for t in rd["tags"]:
                                                        if firstTag:
                                                                outFile.write("\n")
                                                                firstTag = False      
                                                        else:
                                                                outFile.write(" ")
                                                        outFile.write(t)
                                        outFile.write('"""@en')
                                
                                for dd in item["cve"]["description"]["description_data"]:
                                        value = dd["value"]
                                        if "\\" in value: value = value.replace("\\", "\\\\\\\\")
                                        if '"' in value: value = value.replace('"', '\\"')
                                        value = value.replace("\n", " ")
                                        value = value.replace("\n", " ")
                                        value = value.replace("\t", " ")
                                        while "  " in value:
                                                value = value.replace("  ", " ")
                                        outFile.write(' ;\n\t:description "' + value + '"@' + dd["lang"])
                                outFile.write(" ;\n\trdf:type :CVE")
                                generateProps(item)
                                count += 1
                        outFile.close()
                        if isModified:
                                if onlyModifiedCVEs:
                                        resultQueue.put(modified)
                                else:
                                        resultQueue.put(count)
                                        resultQueue.put(modified)
                        else:
                                resultQueue.put(count)
                        feedName = inQueue.get()
                resultQueue.put("DONE")
#End processFeed(inQueue, resultQueue, cpeFeeds, modified = None, onlyModifiedCVEs = False)

def validateJSON(fn, sn, log = None):
    with open(fn, "r", encoding="utf-8") as inFile:
        data = json.load(inFile)
    with open(sn, "r", encoding="utf-8") as inFile:
        schema = json.load(inFile)
    try:
       validate(data, schema)
    except jsonschema.exceptions.ValidationError as err:
        if log is None:
                print(err)
        else:
                log.write(err)
        return False
    return True      

def main(download, feeds):
        
        def downloadNVD():
                def is_downloaded(name):
                        with urllib.request.urlopen("https://nvd.nist.gov/feeds/json/cve/1.1/" + name) as response:
                                contents = response.read()
                                lines = contents.decode("utf-8").split("\n")
                                newDate = datetime.fromisoformat(lines[0].replace("lastModifiedDate:", ""))

                        fileName = "data/" + name
                        if not os.path.exists(fileName):
                                with open(fileName, 'wb') as outFile:
                                        outFile.write(contents)
                                return False
                        
                        with open(fileName, 'r', encoding="utf-8") as inFile:
                                oldDate = datetime.fromisoformat(inFile.readline().rstrip("\n").replace("lastModifiedDate:", ""))
                        if newDate > oldDate:
                                with open(fileName, 'wb') as outFile:
                                        outFile.write(contents)
                                        return False
                        return True
                #End of is_downloaded(name)

                def download(url, fileName):
                        print(url)
                        with urllib.request.urlopen(url) as response:
                                contents = response.read()
                                with open(fileName, mode='wb') as out_file:
                                        out_file.write(contents)
                        with zipfile.ZipFile(fileName, 'r') as zip_ref:
                            zip_ref.extractall(path="data")
                #End of download(url, filename)
                
                for year in range(2002, datetime.now().year + 1):
                        baseName = "nvdcve-1.1-" + str(year)
                        if is_downloaded(baseName + ".meta"):
                                print("Downloaded: " + "https://nvd.nist.gov/feeds/json/cve/1.1/" + baseName + ".json.zip")
                                continue
                        baseName = baseName + ".json.zip"
                        download("https://nvd.nist.gov/feeds/json/cve/1.1/" + baseName, "data/" + baseName)

                download("https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-modified.json.zip", "data/nvdcve-1.1-modified.json.zip")
                download("https://nvd.nist.gov/feeds/json/cpematch/1.0/nvdcpematch-1.0.json.zip", "data/nvdcpematch-1.0.json.zip")
        #End of downloadNVD()
                    
        print("NVD Ontology Generator, Version 4.3")
        start = datetime.now()
        print(start)
        if download:
                print("Download NVD")
                downloadNVD()
        
        print("Load CPE Feeds")
        ifn = "data/nvdcpematch-1.0.json"
        if not validateJSON(ifn, "data/nvd_cpematch_feed_json_1.0.schema"):
                print("Bad CPE feeds.")
                return
        with open(ifn, "r", encoding="utf-8") as inFile:
                cpeFeed = json.loads(inFile.read())
        #cpeFeeds is a dictionary. cpe23Uri represents a CPE match pattern. cpe_name is a list of CPEs from the CPE Dictionary.
        #The keys are formed by concatanating all keys (without cpe_name) and their values in def_cpe_match.
        #The value is the list of all CPE names found in cpe_name.
        #CPE feeds is expected to be formed in accordance with the schema: cpe23Uri and cpe_name are required. 
        cpeFeeds = dict()
        for match in cpeFeed["matches"]:
                #Form the key.
                keys = sorted(match)
                keys.remove("cpe_name")
                key = ""
                for k in keys:
                        key += k + match[k]
                #Form the value for the key appending all CPEs from this match.
                cpes = list()
                for e in match["cpe_name"]:
                        cpes.append(e["cpe23Uri"])
                if len(cpes) == 0: cpes = [match["cpe23Uri"]]
                cpeFeeds[key] = cpes
        cpeFeed = None

        inQueue = Queue()
        resultQueue = Queue()
                
        print("Load json dictionaries:")
        counts = 0
        count = 0
        processModified = "modified" in feeds
        if processModified: print("Modified")
        p = Process(name = "Modified", target = processFeed, args = (inQueue, resultQueue, cpeFeeds, None, not processModified))
        p.start()
        inQueue.put("modified")
        inQueue.put("DONE")
        if processModified: count = resultQueue.get()
        modified = resultQueue.get()
        resultQueue.get() #get DONE
        p.join()

        counts += count      
        try:
                feeds.remove("modified")
        except ValueError:
                pass
        nf = len(feeds)
        if nf > 0:
                processes = []
                np = cpu_count()
                np = nf if nf < np else np
                for i in range(np):
                        p = Process(name = "Process " + str(i), target = processFeed, args=(inQueue, resultQueue, cpeFeeds, modified))
                        processes.append(p)
                        p.start() 
                
                for feed in feeds:
                        if feed == "modified": continue
                        inQueue.put(feed)
                        print(feed)
                for i in range(np):
                        inQueue.put("DONE")

                print("Get from the queue the number of processed CVEs.")
                count = np
                while count > 0:
                        val = resultQueue.get()
                        if val  == "DONE":
                                count -= 1
                        else:
                                counts += val
                print("Join the processes.")
                for i in range(np):
                        processes[i].join()
        print(f"CVEs: {counts}")                                
        print("Loaded all dictionaries")
        end = datetime.now()
        print(end)
        print(f"NVD Ontology Generator Elapsed: {end - start}")

if __name__ == "__main__":
        freeze_support()
        feeds = ["modified"]
        feeds.extend(map(str, range(2002, datetime.now().year + 1)))
        parser = argparse.ArgumentParser()
        parser.add_argument('-d', '--download', action="store_true", help='download input from the Web')
        parser.add_argument('-f', '--feed', action="append", default=[], choices=feeds, help='specify feeds to process')
        args = parser.parse_args()
        if args.feed == []:
                main(args.download, feeds)
        else:
                sFeeds = set(args.feed)
                for f in sFeeds:
                        if f.lower() not in feeds:
                                print("No such a feed: " + f)
                                quit()
                main(args.download, list(sFeeds))
